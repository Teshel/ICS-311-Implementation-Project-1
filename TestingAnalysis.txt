ICS 311 - Testing Analysis for Implementation Project 1.
by Joseph Michaels

Resulting data of "runtest" from my machine are in the files SortedData.txt and UnsortedData.txt. The output tables are separated by Dynamic Set because it was easier to analyze it that way. Analysis of each Dynamic Set follows.

The most noticeable thing is that n=1000 is faster than n=100 for insert() and search() for every Dynamic Set, and for either unsorted or sorted input data. This best explanation I can come up with is that that particular data is easier to search though, for the algorithms in this implementation. n=10000, however, is slower that n=100 and n=1000 in almost every case.

The big exception there is for the unsorted data, Skip List results. The discrepancy there is not really surprising though, since the random choice of that algorithm will have random results (albeit good efficiency on average, according to the theory). Skip List insertion is supposed to be log(n) on average, but in this data there is really not a good correlation with n. In fact, for the sorted data there is no good correlation with n for any of the results, because the n=100000 runtest ran out of memory, and n=1000 is faster than n=100, so there are too few reliable data points.

With the unsorted data, the n=10000 runtest was able to complete, and there is more of a correlation between increasing n and increasing the time it takes for insert and search. However, there are still many discrepancies at n=1000. This is especially true for search. Between the sorted and the unsorted, it highly depends on the Dynamic Set implementation, and n. However, for several of them, the unsorted data is searched faster than sorted data.

For the maximum method, several Dynamic set implementations increase linearly with n. The linked list does, for both sorted and unsorted data. This makes sense, since I did not implement a tail variable, it has to iterate over every item to find the max. For the other Dynamic Sets, however, the maximum method takes constant time or nearly constant time. Skip Lists can find the maximum very quickly by simply going to the right of the top-left-most node (which acts as a head in my implementation), and then moving downwards until the bottom.

The minimum, successor and predecessor methods are constant for every Dynamic Set except the Binary Search Tree (BST), because they all have links between adjacent key-ordered nodes. For the Binary Search Tree, these are supposed to be O(lg n) according to the literature, but they appears to be constant for the data sets used here.

In conclusion, this analysis could be much improved upon by running many more tests at different values of n, such as n=500, n=1500, n=5000, etc. This would help eliminate so many discrepancies.